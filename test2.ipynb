{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"banking77\"\n",
    "\n",
    "path = f\"./results/{task}/\"\n",
    "\n",
    "for seed in os.listdir(path):\n",
    "    p = os.path.join(path,seed)\n",
    "    shot_p = os.path.join(p, \"100shots\")\n",
    "    with open(os.path.join(p, \"zs_result.json\"), 'r', encoding='utf-8') as f:\n",
    "        zs = json.load(f)\n",
    "    with open(os.path.join(shot_p, \"fs_result.json\"), 'r', encoding='utf-8') as f:\n",
    "        fs = json.load(f)\n",
    "    with open(os.path.join(shot_p, \"task_vector_result.json\"), 'r', encoding='utf-8') as f:\n",
    "        task_vector = json.load(f)\n",
    "    with open(os.path.join(shot_p, \"diff_icv_baseline_result.json\"), 'r', encoding='utf-8') as f:\n",
    "        diff_icv_baseline = json.load(f)\n",
    "    with open(os.path.join(shot_p, \"stacked_diff_icv_result.json\"), 'r', encoding='utf-8') as f:\n",
    "        diff_icv = json.load(f)\n",
    "    zs_df = pd.DataFrame(zs['result'])\n",
    "    fs_df = pd.DataFrame(fs['result'])\n",
    "    task_vector_df = pd.DataFrame(task_vector['result'])\n",
    "    diff_icv_baseline_df = pd.DataFrame(diff_icv_baseline['result'])\n",
    "    diff_icv_df = pd.DataFrame(diff_icv['result'])\n",
    "\n",
    "    os.makedirs(os.path.join(p,\"excels\"), exist_ok=True)\n",
    "    zs_df.to_excel(os.path.join(p,\"excels\",\"zs_result.xlsx\"), index=False, engine='openpyxl')\n",
    "    fs_df.to_excel(os.path.join(p,\"excels\",\"fs_result.xlsx\"), index=False, engine='openpyxl')\n",
    "    task_vector_df.to_excel(os.path.join(p,\"excels\",\"task_vector_result.xlsx\"), index=False, engine='openpyxl')\n",
    "    diff_icv_baseline_df.to_excel(os.path.join(p,\"excels\",\"diff_icv_baseline_result.xlsx\"), index=False, engine='openpyxl')\n",
    "    diff_icv_df.to_excel(os.path.join(p,\"excels\",\"stacked_diff_icv_result.xlsx\"), index=False, engine='openpyxl')\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.31\n",
      "33.38\n",
      "32.78\n",
      "32.49\n",
      "_____________\n",
      "32.79\n",
      "34.36\n",
      "32.27\n",
      "32.49\n",
      "_____________\n",
      "32.81\n",
      "32.2\n",
      "32.66\n",
      "32.49\n",
      "_____________\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3.1-8B-Instruct\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "task = \"wmt19\"\n",
    "\n",
    "path = f\"./results/{task}/\"\n",
    "\n",
    "for seed in ['42','41', '40']:\n",
    "    p = os.path.join(path,seed)\n",
    "    shot_p = os.path.join(p, \"50shots\")\n",
    "    with open(os.path.join(p, \"zs_result.json\"), 'r', encoding='utf-8') as f:\n",
    "        zs = json.load(f)\n",
    "    with open(os.path.join(shot_p, \"fs_result.json\"), 'r', encoding='utf-8') as f:\n",
    "        fs = json.load(f)\n",
    "    # with open(os.path.join(shot_p, \"task_vector_result.json\"), 'r', encoding='utf-8') as f:\n",
    "    #     task_vector = json.load(f)\n",
    "    # with open(os.path.join(shot_p, \"diff_icv_baseline_result.json\"), 'r', encoding='utf-8') as f:\n",
    "    #     diff_icv_baseline = json.load(f)\n",
    "    with open(os.path.join(shot_p, \"stacked_diff_icv_result.json\"), 'r', encoding='utf-8') as f:\n",
    "        diff_icv = json.load(f)\n",
    "    prediction = []\n",
    "    for item in fs['result']:\n",
    "        cp = item['cleaned_prediction']\n",
    "        prediction.append(len(tokenizer.encode(cp, add_special_tokens=False)))\n",
    "    print(sum(prediction)/len(prediction))\n",
    "    \n",
    "    prediction = []\n",
    "    for item in zs['result']:\n",
    "        cp = item['cleaned_prediction']\n",
    "        prediction.append(len(tokenizer.encode(cp, add_special_tokens=False)))\n",
    "    print(sum(prediction)/len(prediction))\n",
    "\n",
    "    prediction = []\n",
    "    gt = []\n",
    "    for item in diff_icv['result']:\n",
    "        cp = item['cleaned_prediction']\n",
    "        g = item['gt']\n",
    "        prediction.append(len(tokenizer.encode(cp, add_special_tokens=False)))\n",
    "        gt.append(len(tokenizer.encode(g, add_special_tokens=False)))\n",
    "    print(sum(prediction)/len(prediction))\n",
    "    print(sum(gt)/len(gt))\n",
    "    print(\"_____________\")\n",
    "\n",
    "    \n",
    "    # print(fs['score'])\n",
    "    # print(zs['score'])\n",
    "    # print(task_vector['score'])\n",
    "    # print(diff_icv_baseline['score'])\n",
    "    # print(diff_icv['score'])\n",
    "    # print(\"__________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5620724972906133\n",
      "0.49038658474142344\n",
      "______________\n",
      "0.5376993674492714\n",
      "0.5085672022691992\n",
      "______________\n",
      "0.5798339069458021\n",
      "0.5102711335430229\n",
      "______________\n",
      "0.6034542048322757\n",
      "0.5085330667511928\n",
      "______________\n",
      "0.6181320293751987\n",
      "0.5226668933041222\n",
      "______________\n",
      "0.6166076849683407\n",
      "0.5227090730528066\n",
      "______________\n"
     ]
    }
   ],
   "source": [
    "task = \"banking77\"\n",
    "\n",
    "path = f\"./results/{task}/\"\n",
    "\n",
    "for s in [ '10shots', '20shots', '40shots', '60shots', '80shots', '100shots']:\n",
    "    fs_score = []\n",
    "    diff_score = []\n",
    "    for seed in ['42','41', '40']:\n",
    "        p = os.path.join(path,seed)\n",
    "        shot_p = os.path.join(p, s)\n",
    "        with open(os.path.join(shot_p, \"fs_result.json\"), 'r', encoding='utf-8') as f:\n",
    "            fs = json.load(f)\n",
    "        with open(os.path.join(shot_p, \"stacked_diff_icv_result.json\"), 'r', encoding='utf-8') as f:\n",
    "            diff_icv = json.load(f)\n",
    "        fs_score.append(fs['score']['f1-score'])\n",
    "        diff_score.append(diff_icv['score']['f1-score'])\n",
    "    print(sum(fs_score)/len(fs_score))\n",
    "    print(sum(diff_score)/len(diff_score))\n",
    "    print(\"______________\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[25.40621733694498, 27.409918706859195, 25.628319570146655]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
