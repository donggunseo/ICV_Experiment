{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a233cafc55f4e0b8c02d58889c72bd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Meta-Llama-3.1-8B-Instruct\", torch_dtype = torch.float16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3.1-8B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"You are an intelligent assistant trained to classify customer queries into predefined intent categories. Your task is to read a customer's query and assign it to the most appropriate intent category from the following list of intent categories:\\n1.activate_my_card\\n2.age_limit\\n3.apple_pay_or_google_pay\\n4.atm_support\\n5.automatic_top_up\\n6.balance_not_updated_after_bank_transfer\\n7.balance_not_updated_after_cheque_or_cash_deposit\\n8.beneficiary_not_allowed\\n9.cancel_transfer\\n10.card_about_to_expire\\n11.card_acceptance\\n12.card_arrival\\n13.card_delivery_estimate\\n14.card_linking\\n15.card_not_working\\n16.card_payment_fee_charged\\n17.card_payment_not_recognised\\n18.card_payment_wrong_exchange_rate\\n19.card_swallowed\\n20.cash_withdrawal_charge\\n21.cash_withdrawal_not_recognised\\n22.change_pin\\n23.compromised_card\\n24.contactless_not_working\\n25.country_support\\n26.declined_card_payment\\n27.declined_cash_withdrawal\\n28.declined_transfer\\n29.direct_debit_payment_not_recognised\\n30.disposable_card_limits\\n31.edit_personal_details\\n32.exchange_charge\\n33.exchange_rate\\n34.exchange_via_app\\n35.extra_charge_on_statement\\n36.failed_transfer\\n37.fiat_currency_support\\n38.get_disposable_virtual_card\\n39.get_physical_card\\n40.getting_spare_card\\n41.getting_virtual_card\\n42.lost_or_stolen_card\\n43.lost_or_stolen_phone\\n44.order_physical_card\\n45.passcode_forgotten\\n46.pending_card_payment\\n47.pending_cash_withdrawal\\n48.pending_top_up\\n49.pending_transfer\\n50.pin_blocked\\n51.receiving_money\\n52.refund_not_showing_up\\n53.request_refund\\n54.reverted_card_payment\\n55.supported_cards_and_currencies\\n56.terminate_account\\n57.top_up_by_bank_transfer_charge\\n58.top_up_by_card_charge\\n59.top_up_by_cash_or_cheque\\n60.top_up_failed\\n61.top_up_limits\\n62.top_up_reverted\\n63.topping_up_by_card\\n64.transaction_charged_twice\\n65.transfer_fee_charged\\n66.transfer_into_account\\n67.transfer_not_received_by_recipient\\n68.transfer_timing\\n69.unable_to_verify_identity\\n70.verify_my_identity\\n71.verify_source_of_funds\\n72.verify_top_up\\n73.virtual_card_not_working\\n74.visa_or_mastercard\\n75.why_verify_identity\\n76.wrong_amount_of_cash_received\\n77.wrong_exchange_rate_for_cash_withdrawal\\nPlease analyze the query and return the most suitable category from the list above. If the query does not fit perfectly into one category, select the category that best matches the main topic of the query. Only return intent category text and don't return any other words or numbers.\\n\"\n",
    "\n",
    "prompt = instruction + \"Query: I'm pretty sure something went wrong with my exchange. I changed Russian Ruble to UK pounds and was charged way too much!\\nIntent:\"\n",
    "inputs = tokenizer(prompt, return_tensors='pt').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NEW_TOKENS = 50\n",
    "output = model.generate(**inputs, max_new_tokens = MAX_NEW_TOKENS, pad_token_id=tokenizer.eos_token_id, stop_strings = [\"\\n\",\"\\n\\n\",'<|eot_id|>'], tokenizer=tokenizer).detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_str = tokenizer.decode(output.squeeze()[len(inputs.input_ids.squeeze()):])\n",
    "output_str = output_str.lower().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'exchange_charge'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
